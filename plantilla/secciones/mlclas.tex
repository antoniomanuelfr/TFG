\chapter{Clasificación multi-etiqueta}
\label{sec:cml}
Debido a la naturaleza del problema con el que se está trabajando, resulta complejo usar los enfoques explicados en la sección \ref{sec:ml}-\nameref{sec:ml}. Estos enfoques están diseñados para el caso de clasificación multi-etiqueta de tipo binario, no de tipo ordinal. Un ejemplo de la complejidad añadida por este problema seria a la hora de calcular el \textbf{labelset} de una muestra. En este caso, como se conoce que los valores a predecir son $\{1,2,3,4,5,6,7\}$ y con un total de 6 etiquetas. El labelset que se va a usar queda definido como: $\{1,2,3,4,5,6,7\}^6$, dando lugar a una gran cantidad de clases ($7^6 = 117649$ clases).
\section*{Soluciones propuestas}
El proceso para obtener un modelo para este tipo de clasificación es similar al que se ha visto en secciones anteriores, donde la mayor parte de los algoritmos necesitas una fase de entrenamiento inicial y dependiendo de las etiquetas asignadas a cada muestra, se ajustan los parámetros del modelo.
\section{Primera solución: Transformación a clasificación multi-etiqueta binaria}
En este primer caso, se va a proponer simplificar el problema que se está abordando y cambiar el tipo a un problema de clasificación multi-etiqueta binaria. El motivo de esta transformación es corroborar que es posible extraer conocimiento del conjunto de datos simplificado.
Para ello, el procedimiento para simplificar el conjunto de datos es el siguiente:
\begin{itemize}
	\item El rango de cada etiqueta es $[1-7]$.
	\item Se va a suponer que una persona tiene interés cuando el valor de esas etiquetas es mayor que 5.
	\item En caso contrario, se va a marcar la etiqueta como sin interés.
\end{itemize}
Tras realizar esta simplificación, se va a optar por usar \textbf{Binary Relevance} para adaptar el problema simplificado a varios problemas de clasificación binaria.
\subsection{Resultados}
A continuación, se muestran los resultados obtenidos siguiendo este enfoque por cada uno de los algoritmos seleccionados:
\subsubsection*{Árboles de decisión}
A continuación, en la Tabla \ref{tab:ml_tab_dt}, se muestra una tabla que recoge el valor de las métricas obtenidas por Árboles de decisión en los conjuntos de entrenamiento y de test, junto con el valor medio en validación:
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c}
		\cline{1-4}
		Conjunto         & F1 Score & AUC Score & Accuracy \\ \cline{1-4}
		Media Validación & 0.794    & 0.84      & 0.82     \\ \cline{1-4}
		Train            & 0.868    & 0.863     & 0.6      \\ \cline{1-4}
		Test             & 0.86     & 0.85      & 0.593    \\ \cline{1-4}
	\end{tabular}
	\caption{Valores de métricas obtenidas usando BR y Árboles de decisión}
	\label{tab:ml_tab_dt}
\end{table}
Como se ha visto en secciones anteriores, se puede obtener la aportación que ha tenido cada una de las variables que conforma el conjunto de datos a la hora de realizar una predicción. En el caso de BR, se puede obtener recuperando esta información de cada clasificador que ha sido entrenando, obteniendo así la importancia de cada variable por etiqueta clasificada.
A continuación se muestran unas gráficas donde se va a recopilar la siguiente información:
\begin{itemize}
	\item La importancia por cada etiqueta clasificada.
	\item La importancia media de todas las etiquetas clasificadas.
\end{itemize}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{src/feature_importance_dt_br_compare.png}
	\caption{Importancia por etiqueta clasificada.}
	\label{fig:dt_br_label}
\end{figure}
La Figura \ref{fig:dt_br_label} representa la importancia media calculada obteniendo la media de la importancia calculada por los modelos entrenados. Como se pudo ver en secciones anteriores, la importancia de la variable \textbf{AE5} es muy grande en todas las etiquetas que se están intentando clasificar.\\
\linebreak
Aunque con una menor importancia en general, las variables \textbf{ACMedia} y \textbf{SEMedia} también han tenido un contribución a la hora de generar el modelo.\\
\clearpage
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{src/feature_importance_dt_br_mean.png}
	\caption{Importancia por etiqueta clasificada.}
	\label{fig:dt_br_mean}
\end{figure}
Completando esta sección de la importancia de las variables, la Figura \ref{fig:dt_br_mean} representa la importancia media calculada obteniendo la media de la importancia calculada por los modelos entrenados. Como se pudo ver en secciones anteriores, la importancia de la variable \textbf{AE5} es muy grande en todas las etiquetas que se están intentando clasificar.\\
\linebreak
Continuando con el análisis de los resultados, se van a mostrar las matrices de confusión por cada una de las etiquetas que se están usando.
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE1_dt_br.png}
		\caption{IE1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE2_dt_br.png}
		\caption{IE2}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE3_dt_br.png}
		\caption{IE3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE4_dt_br.png}
		\caption{IE4}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE5_dt_br.png}
		\caption{IE5}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE6_dt_br.png}
		\caption{IE6}
	\end{subfigure}
	\caption{Matrices de confusión para los distintos clasificadores entrenados (AD)}
	\label{fig:ml_conf_matrix_dt}
\end{figure}
En las Figura \ref{fig:ml_conf_matrix_dt}, se puede ver como para todas las etiquetas se han clasificado una gran cantidad de variables positivas, mientras que parece que al modelo le ha costado predecir los valores negativos. \\
En general, los resultados son buenos y consistentes para todas las etiquetas.
\clearpage
\subsubsection*{Random Forest}
Continuando con el análisis de resultados usando el enfoque de Binary Relavance, en la Tabla \ref{tab:ml_tab_rf} se muestran los obtenidos por Random Forest.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c}
		\cline{1-4}
		Conjunto         & F1 Score & AUC Score & Accuracy \\ \cline{1-4}
		Media Validación & 0.807    & 0.892     & 0.827    \\ \cline{1-4}
		Train            & 0.998    & 1         & 0.99     \\ \cline{1-4}
		Test             & 0.876    & 0.9       & 0.61     \\ \cline{1-4}
	\end{tabular}
	\caption{Valores de métricas obtenidas usando BR y Random Forest}
	\label{tab:ml_tab_rf}
\end{table}
Como se ha visto en secciones anteriores, se puede obtener la aportación que ha tenido cada una de las variables que conforma el conjunto de datos a la hora de realizar una predicción. En el caso de BR, se puede obtener recuperando esta información de cada clasificador que ha sido entrenando, obteniendo así la importancia de cada variable por etiqueta clasificada.
A continuación se muestran unas gráficas donde se va a recopilar la siguiente información: \linebreak
\begin{itemize}
	\item La importancia por cada etiqueta clasificada.
	\item La importancia media de todas las etiquetas clasificadas.
\end{itemize}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{src/feature_importance_rf_br_compare.png}
	\caption{Importancia por etiqueta clasificada.}
	\label{fig:rf_br_label}
\end{figure}
En la Figura \ref{fig:rf_br_label} se puede observar la importancia de cada variable separando por etiqueta que se esta clasificando. A diferencia de la vista en Árboles de Decisión, se observa una mayor cantidad de variables, aunque se puede ver que las variables \textbf{AE5} y \textbf{ACMedia} siguen siendo preguntas muy importantes, pero hay variables como el \textbf{curso}, \textbf{nota}, \textbf{AC1}, etc que no han estado presentes en la grafica de Árboles de Decisión.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{src/feature_importance_rf_br_mean.png}
	\caption{Importancia por etiqueta clasificada.}
	\label{fig:rf_br_mean}
\end{figure}
Completando el análisis sobre la importancia de las variables que forman el problema, en la Figura \ref{fig:rf_br_mean} se puede observar la importancia media calculada obteniendo la media de la importancia calculada por los modelos entrenados.\\
Se puede observar como las variables \textbf{AE5} y \textbf{ACMedia} son las variables que han sido más relevantes a la hora de que el modelo Random Forest prediga las múltiples etiquetas.
\clearpage
A continuación se puede observar las matrices de confusión por cada una de las etiquetas que se está clasificando:
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE1_rf_br.png}
		\caption{IE1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE2_rf_br.png}
		\caption{IE2}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE3_rf_br.png}
		\caption{IE3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE4_rf_br.png}
		\caption{IE4}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE5_rf_br.png}
		\caption{IE5}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE6_rf_br.png}
		\caption{IE6}
	\end{subfigure}
	\caption{Matrices de confusión para los distintos clasificadores entrenados (RF)}
	\label{fig:ml_conf_matrix_rf}
\end{figure}
En la Figura \ref{fig:ml_conf_matrix_rf}, se puede ver un comportamiento similar al visto en Árboles de decisión, donde se ha clasificado correctamente valores positivos, más dificultades a la hora de predecir valores negativos, pero no tantos problemas como los que se han observado en Árboles de Decisión, donde en muchos de los casos se podía apreciar una mayor cantidad de fallos en estos valores.\\
\linebreak
También se aprecia que los resultados son consistentes para todas las etiquetas clasificadas, por lo que podemos afirmar que este modelo ha sido capaz de extraer conocimiento del conjunto de datos.
\clearpage
\subsubsection*{Support Vector Machines}
Finalmente, se muestran los resultados del uso de SVM en usando el método Binary Relevance:
Como SVM no puede recuperar la importancia de cada característica, estas gráficas se han omitido.\\
\linebreak
En la Tabla \ref{tab:ml_tab_svc} se muestran los resultados obtenidos usando las métricas seleccionadas.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c}
		\cline{1-4}
		Conjunto         & F1 Score & AUC Score & Accuracy \\ \cline{1-4}
		Media Validación & 0.801    & 0.902     & 0.828    \\ \cline{1-4}
		Train            & 0.889    & 0.922     & 0.624    \\ \cline{1-4}
		Test             & 0.866    & 0.896     & 0.605    \\ \cline{1-4}
	\end{tabular}
	\caption{Valores de métricas obtenidas usando BR y SVM}
	\label{tab:ml_tab_svc}
\end{table}
En la siguiente figura se muestran las distintas matrices de confusión para cada una de las etiquetas que componen el conjunto de datos.
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE1_svc_br.png}
		\caption{IE1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE2_svc_br.png}
		\caption{IE2}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE3_svc_br.png}
		\caption{IE3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE4_svc_br.png}
		\caption{IE4}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE5_svc_br.png}
		\caption{IE5}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/confusion_matrix_IE6_svc_br.png}
		\caption{IE6}
	\end{subfigure}
	\caption{Matrices de confusión para los distintos clasificadores entrenados (SVM)}
	\label{fig:ml_conf_matrix_svc}
\end{figure}
En la Figura \ref{fig:ml_conf_matrix_svc} se vuelve a repetir el comportamiento observado, para valores positivos se ha conseguido predecir correctamente una buena parte de las muestras pertenecientes a esta clase, y de manera consistente por todas las etiquetas que se están clasificando.\\
También se aprecia como parece que para valores negativos, el modelo vuelve a algunas dificultades.
\subsection{Conclusiones}
Como se puede observar por los resultados obtenidos, usando este enfoque para resolver el problema que se afronta ha resultado en unos buenos resultados y en la obtención de bastante información que puede ser relevante para el análisis de este caso.\\
\linebreak
Comentando los resultados, se puede observar como en las medidas de F1 Score y AUC se han obtenido unos resultados constantes y con valores buenos, mostrando un buen rendimiento en general.\\
Respecto a Accuracy, a primera vista, los resultados obtenidos han sido peores obteniendo un resultado (para todos los algoritmos) alrededor de 60\%.\\
Este comportamiento llama mucho la atención, y tiene la siguiente explicación: Cuando se considera esta métrica en el caso de multi-etiqueta, el número de casos favorables se va a obtener obteniendo el número de muestras para las que el algoritmo ha clasificado correctamente \textbf{TODAS} las etiquetas de cada muestra.\\ Este es un reflejo del aumento de complejidad en este tipo de problemas.\\
En mi opinión, esta métrica no refleja realmente el rendimiento de los algoritmo, puesto que si el algoritmo se equivoca en una única etiqueta de todas las posibles, esa muestra se va a considerar como mal clasificada y va reducir bastante el valor de la métrica.\\
\linebreak
Revisando las matrices de confusión, se puede observar la misma tendencia en los distintos modelos que se han entrenado: Se ha clasificado correctamente los casos en los que la variable es positiva y se ha encontrado más problemas en los casos en los que la variable es negativa. Revisando la Figura 	\ref{tab:ocurrencia_valores}-\nameref{tab:ocurrencia_valores} y teniendo en cuenta la división que se ha realizado sobre el conjunto, se puede observar que la mayor parte de datos esta localizada en los valores más altos mientras que los más bajos tienen un menor número de muestras.\\
Esta característica del conjunto de datos con el que se está trabajando se refleja en que usando Árboles de Decisión ha tenido un peor rendimiento a la hora de clasificar la clase minoritaria (se puede observar en la Figura \ref{fig:ml_conf_matrix_dt}) en aquellas etiquetas clasificadas como clase negativa (exceptuando IE3, donde se ha podido observan un rendimiento bueno en la clase negativa).\\
Revisando los resultados obtenidos por los algoritmos que han demostrado ser más robustos (SVM y Random Forest), se puede observar como se han obtenido mejores resultados clasificando un porcentaje mayor correctamente de la clase negativa de cada etiqueta.\\
\linebreak
La parte que más interés tiene (en mi opinión) es la importancia de características, ya que en este caso se ha obtenido que variables son las mas influyentes por cada una de las etiquetas que forman el conjunto de datos. Se va a añadir un análisis más exhaustivo sobre estos resultados en la sección \ref{sec:conclusiones}-\nameref{sec:conclusiones}
\clearpage
\section{Segunda solución: Entrenar clasificadores ordinales por etiqueta}
se va a usar uno de los enfoques más simples. Se va a entrenar un clasificador ordinal por cada variable.
Dado que puede existir relaciones entre etiquetas, la principal desventaja de este enfoque es que no se tiene en cuenta esta relación, perdiendo así información que puede ser importante.\\
\linebreak
En el problema que se está abordando en este trabajo, estas variables son de tipo ordinal, por lo que se va a hacer uso del clasificador desarrollado en \ref{sec:ord}-\nameref{sec:ord}.
Respecto al pre-procesamiento, se va a usar el mismo proceso explicado en \ref{sec:pre}-\nameref{sec:pre}.\\

Para realizar este enfoque, se ha optado por crear una nueva serie de clasificadores multi-etiqueta que sean compatible con la funcionalidad que incluye Scikit-Learn. Este proceso se explicará en la sección \ref{sec:sftw-mlc}-\nameref{sec:sftw-mlc}. Para ello se han usados los algoritmos con los que se ha trabajado en las secciones anteriores para modelar esta posible solución.
\subsection{Resultados}
Al igual que en los enfoques que se han presentado en secciones anteriores, se han seleccionado los siguientes modelos:
\begin{itemize}
	\item \textbf{Árboles de Decisión.}
	\item \textbf{Random Forest.}
	\item \textbf{SVM.}
\end{itemize}
En las secciones que se muestran a continuación se van a mostrar los resultados obtenidos por cada modelo seleccionado.
\clearpage
\subsubsection*{Árboles de decisión}
Antes de comenzar a mostrar los resultados obtenidos por este modelo, se va a mencionar cuales han sido los parámetros que mejores resultados dieron:
\begin{itemize}
	\item 3 niveles de profundidad máxima.
	\item Máximo de 2 hojas.
\end{itemize}
Como se puede apreciar, se está trabajando con árboles mucho más simples que en el resto de secciones.
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/dt_mlabelcc_train_compare}
		\caption{Métricas obtenidas en conjunto de entrenamiento}
	\end{subfigure}
	\vfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/dt_mlabelcc_test_compare}
		\caption{Métricas obtenidas en conjunto de test}
	\end{subfigure}
	\vfill
	\caption{Metricas obtenidas usando Árboles de Decsión}
	\label{fig:dtml_cmp}
\end{figure} 
En la Figura  \ref{fig:dtml_cmp} se puede observar el comportamiento del modelo en el conjunto de test. Se aprecia como el rendimiento usando este modelo ha sido bastante peor que en el resto de enfoques seleccionados. Se aprecia como en ninguno de los casos se ha superado un valor de $0.25$ para las métricas \textit{F1} y \textit{accuracy}. Podría parecer que el modelo no es lo suficientemente complejo para poder extraer el conocimiento, pero ha medida que se ha incrementado la complejidad del modelo, se ha podido apreciar como el rendimiento ha sido peor.
\clearpage
\subsubsection*{Random Forest}
Continuando con el análisis de los modelos usando este enfoque, a continuación se van a mostrar los resultados obtenidos usando Random Forest.\\
Los parámetros que mejor rendimiento dieron fueron los siguientes:
\begin{itemize}
	\item 7 árboles de decisión formando el bosque.
	\item Se consideran todas las variables para buscar la mejor división.
\end{itemize}
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/rf_mlabelcc_train_compare}
		\caption{Métricas obtenidas en conjunto de entrenamiento}
	\end{subfigure}
	\vfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/rf_mlabelcc_test_compare}
		\caption{Métricas obtenidas en conjunto de test}
	\end{subfigure}
	\vfill
	\caption{Metricas obtenidas usando Random Forest}
	\label{fig:rford_ml_cmp}
\end{figure}
En la Figura \ref{fig:rford_ml_cmp} podemos observar el mismo comportamiento que el observado con Árboles de Decisión. El rendimiento es bastante peor que el que se ha obtenido usando otros enfoques, obteniendo unos resultados por debajo de $0.2$ en las métricas \textit{F1} y \textit{Accuracy}. \\
\linebreak
Debido a este mal comportamiento, queda claro que este enfoque no es valido para resolver este problema, ya que únicamente cuando se han tratado las distintas etiquetas de forma separada, se ha observado una caída en el rendimiento de Árboles de Decisión y Random Forest.
\clearpage
\subsubsection*{SVM}
Para terminar de validar nuestra hipótesis de que este enfoque no es correcto para la resolución de este problema, a continuación se van a mostrar los resultados obtenidos usando SVM.\\
\linebreak
Los parámetros que mejores resultados dieron para las Máquinas de Soporte de Vectores fueron los siguientes:
\begin{itemize}
	\item Grado del polinomio igual a 2.
	\item Coeficiente de regularización igual 1.
\end{itemize}
A continuación se muestran los resultados obtenidos en los conjuntos de entrenamiento y test usando SVM:
\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/SVC_mlabelcc_train_compare}
		\caption{Métricas obtenidas en conjunto de entrenamiento}
	\end{subfigure}
	\vfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{src/SVC_mlabelcc_test_compare}
		\caption{Métricas obtenidas en conjunto de test}
	\end{subfigure}
	\vfill
\caption{Metricas obtenidas usando SVM}
\label{fig:svcml_cmp}
\end{figure}
Como se puede ver en la Figura \ref{fig:svcml_cmp}, se vuelve a repetir el mal comportamiento usando este enfoque, no superando la barrera del $0.25$  en las métricas \textit{F1} y \textit{Accuracy}
\clearpage
\subsubsection*{Conclusiones}
Como se puede observar, los resultados obtenidos usando este enfoque han sido muy malos, independientemente de los modelos seleccionados.
\begin{itemize}
	\item Se puede observar como los modelos no han sido capaces de extraer conocimiento tratando por separado las etiquetas, obteniendo malos resultados incluso prediciendo el conjunto de datos con el que han sido entrenados.
	\item Los modelos que se obtuvieron, no son modelos complejos (árboles de decisión con una profundidad de 2 niveles, SVM usando polinomios de grado 2, Random Forest usando 7 árboles de decisión en el bosque).
	\item Es independiente del algoritmo usado, ya que todos tuvieron un desempeño similar.
\end{itemize}
Observando el rendimiento de los algoritmos usando este enfoque, y comparando con los resultados en secciones anteriores, queda claro que el tratar las variables de manera independiente no es una opción.\\
\linebreak
La principal hipótesis que se maneja para explicar este mal comportamiento es que para el conjunto de datos con el que se esta trabajando, no basta con intentar predecir por separado cada una de las etiquetas, ya que parece que es la \textbf{relación} entre las distintas variables donde está realmente el conocimiento, y no en los valores individuales de cada una de las etiquetas.\\
\linebreak
Viendo estos resultados, se va a descartar este enfoque, ya que como se ha mencionado previamente, no es el enfoque adecuado para resolver este tipo de clasificación usando el conjunto de datos con el que se está trabajando.
