{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd08da3c9b99527ca35eba42b7eabae80f173aece1b8bbc5e117d6490913712d5b1",
   "display_name": "Python 3.9.4 64-bit ('TFG')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Uso de árboles de decisión para predecir la intención emprendedora media\n",
    "En esta sección vamos a ver como se comportan los arboles de decisión con nuestro dataset. Vamos a empezar por estos ya que tienen la ventaja de ser algoritmos de los que podemos extraer información facilmente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "parent_path = str(Path.cwd().parents[0])\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 score para train 1.0\nR2 score para test 0.4605200296406381\nNivel alcanzado 20 número de hojas 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from src import manual_preprocessing as mp\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "x_train = pd.read_csv(join(mp.data_path, 'x_train.csv'))\n",
    "y_train = pd.read_csv(join(mp.data_path, 'y_train.csv'))\n",
    "x_test = pd.read_csv(join(mp.data_path, 'x_test.csv'))\n",
    "y_test = pd.read_csv(join(mp.data_path, 'y_test.csv'))\n",
    "y_cols = y_train.columns\n",
    "\n",
    "c_cols, n_cols = mp.get_columns_type(x_train)\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                            ('encoder', OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('numerical',  KNNImputer(n_neighbors=2, weights='uniform'), n_cols),\n",
    "                                                ('categorical', categorical_transformer, c_cols)])\n",
    "y_imputer = SimpleImputer(strategy='median')\n",
    "y_train = y_imputer.fit_transform(y_train)\n",
    "y_test = y_imputer.transform(y_test)\n",
    "\n",
    "y_train_final = pd.DataFrame(y_train, columns=y_cols)\n",
    "y_test_final = pd.DataFrame(y_test, columns=y_cols)\n",
    "\n",
    "x_train_final = preprocessor.fit_transform(x_train)\n",
    "x_test_final = preprocessor.transform(x_test)\n",
    "\n",
    "clf = DecisionTreeRegressor(random_state=0).fit(x_train_final, y_train_final['IEMedia'])\n",
    "y_pred = clf.predict(x_test_final)\n",
    "y_train_pred = clf.predict(x_train_final)\n",
    "\n",
    "print(f\"R2 score para train {r2_score(y_train_final['IEMedia'], y_train_pred)}\")\n",
    "print(f\"R2 score para test {r2_score(y_test_final['IEMedia'], y_pred)}\")\n",
    "print(f\"Nivel alcanzado {clf.get_depth()} número de hojas {clf.get_depth()}\")\n"
   ]
  },
  {
   "source": [
    "Como podemos ver, tenemos un score en train del 100% pero un score de test de un 40%. Esto nos dice que claramente el modelo ha sufrido de sobre-aprendizaje. El árbol de decision de Scikit-Learn no tiene un límite en los niveles que puede crear, asi que empezo a crear tantos niveles hasta que separó completamente el conjunto de datos. Para evitar esto, vamos a ver cual es el número de niveles que tiene este árbol, y empezar a entrenar modelos limitando el número de niveles permitido para el árbol."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best score 0.6855982980945945 with DecisionTreeRegressor(max_depth=8, max_leaf_nodes=20)\nR2 score para train 0.7649887652485289\nR2 score para test 0.7015585393801441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [2, 4, 8, 9, 10, 16],\n",
    "              'max_leaf_nodes': [2, 4, 8, 16, 20, 22]}\n",
    "\n",
    "g_search = GridSearchCV(DecisionTreeRegressor(), param_grid=param_grid, scoring='r2')\n",
    "\n",
    "g_search.fit(x_train_final, y_train_final['IEMedia'].to_numpy())\n",
    "print(f\"Best score {g_search.best_score_} with {g_search.best_estimator_}\")\n",
    "best = g_search.best_estimator_\n",
    "\n",
    "best.fit(x_train_final, y_train_final['IEMedia'])\n",
    "y_pred = best.predict(x_test_final)\n",
    "y_train_pred = best.predict(x_train_final)\n",
    "\n",
    "\n",
    "print(f\"R2 score para train {r2_score(y_train_final['IEMedia'], y_train_pred)}\")\n",
    "print(f\"R2 score para test {r2_score(y_test_final['IEMedia'], y_pred)}\")\n"
   ]
  },
  {
   "source": [
    "Ahora que tenemos un modelo que podemos considerar bueno, podemos usar ese modelo para obtener, por ejemplo, la importancia de cada columna que ha encontrado el algoritmo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "feature_importances = pd.Series(data=clf.feature_importances_, index=x_train.columns)\n",
    "print(feature_importances.sort_values(ascending=False)[:9])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SE5                    0.554482\nSE6                    0.133386\nEdad                   0.032329\nEmpFut                 0.014038\nCEF9                   0.012134\nEmpFam                 0.012049\nActive Saving (QF3)    0.010590\nSEMedia                0.010282\nNota                   0.008718\ndtype: float64\n"
     ]
    }
   ]
  },
  {
   "source": [
    "A partir de los resultados anteriores, podemos ver que variables influyen más en la intención emprendedora media:\n",
    "\n",
    "- `SE5`: Conozco cómo desarrollar un proyecto empresarial.\n",
    "- `SE6`: Si intentara iniciar una empresa, tendría una alta probabilidad de éxito.\n",
    "- `Edad`: Edad del encuestado.\n",
    "- `EmpFut`: Actualmente, el encuestado está tratando iniciar un negocio o ser autoempleado.\n",
    "- `CEF9`: Preguntas sobre Conocimientos financieros empresariales\n",
    "- `EmpFam`: Hay algún emprendedor en la familia del encuestado\n",
    "- `Active Saving`: Ahorro activo.\n",
    "- `SEMedia`: Variable global de Autoeficacia emprendedora\n",
    "- `Nota`: Nota media del expediente \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}