{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd08da3c9b99527ca35eba42b7eabae80f173aece1b8bbc5e117d6490913712d5b1",
   "display_name": "Python 3.9.4 64-bit ('TFG')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import sys\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "parent_path = str(Path.cwd().parents[0])\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)\n",
    "\n",
    "from src import manual_preprocessing as mp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "source": [
    "# Analisis exploratorio de los datos\n",
    "En esta sección vamos a abordar la primera fase del proceso del analisis de datos. Vamos a estudiar a fondo el dataset que se nos ha entregado y comenzar a conocer el problema y hacer un procesamiento manual de los datos.\n",
    "\n",
    "### Comprobacion de columnas con mismos datos\n",
    "\n",
    "Tras una exhauctiva lectura de la explicacion de cada variable, me  he dado cuenta que hay un grupo de columnas que son problematicas, estas columnas son las BFx y las BFxAdaptada. \n",
    "\n",
    "En las columnas BFx tenemos unicamente datos que se recogieron en el año `19_20` y en las columnas BFxAdaptada tenemos datos que se recogieron en `19_20` y en `18_19`. Esto es un problema ya que puede ser que haya datos que no se corresponden entre las dos columnas. Para comprobarlo he creado la funcion de abajo a la que se le dan todos los datos y comprueba si dos columnas son iguales.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Las columnas son iguales, shape actual = (1672, 246)\n"
     ]
    }
   ],
   "source": [
    "# Lectura de datos\n",
    "dataset = pd.read_csv(join(mp.data_path, 'data.csv'))\n",
    "list_adaptada = ['BF1Adaptada', 'BF2Adaptada', 'BF3Adaptada', 'BF4Adaptada']\n",
    "list_no_adaptada =  ['BF1', 'BF2', 'BF3', 'BF4']\n",
    "res_data = mp.compare_columns(dataset, list_adaptada, list_no_adaptada, 'Año', '19_20', int)\n",
    "\n",
    "if res_data is not None:\n",
    "    print(f\"Las columnas son iguales, shape actual = {res_data.shape}\")\n",
    "    dataset = res_data\n",
    "else:\n",
    "    print(\"Las columnas son distintas\")"
   ]
  },
  {
   "source": [
    "### Eleccion de columnas redundantes.\n",
    "\n",
    "En esta sección, vamos a analizar una por una que columnas son redundantes y proceder a la eliminación de las mismas, ya que aunque no tenemos un dataset grande, no deberiamos tener columnas conteniendo la misma informacion.\n",
    "\n",
    "Vamos a comenzar por borrar algunas de las columnas `CF2`, `CF4`, `CF5` ya que son respuestas libres. Intentar categorizar este tipo de columnas implicaria un gran coste, debido al número de posibles respuestas de cada uno de los encuestados. Ademas, ya tenemos en las columas QFx valores 0,1 si las preguntas anteriores estan contestadas bien. Las columnas que se van a dejar son: \n",
    "\n",
    "- `CF1`: Esta se deja ya que es una pregunta en escala Likert \n",
    "- `CF3`: Esta es una pregunta con opciones. La columna `QF3` asociada tambien se va a dejar, ya que indica si la respuesta es correcta o no. Esta columna tiene interés.\n",
    "- `CF6`: Igual que `CF3`\n",
    "\n",
    "Las variables `BFx` representan la respuesta a una pregunta de la encuesta. Tenemos dos de esas preguntas que son de verdadero o falso, asi que esas columnas van a ser borradas. El resto, son preguntas con opciones, y estas columnas pueden ser interesantes. Las columnas que se van a borrar son:\n",
    "\n",
    "- `Los dividendos son parte de lo que una empresa paga al banco para devolver un préstamo.`\n",
    "- `Cuando una empresa obtiene capital de un inversor, le está dando al inversor parte de la propiedad de la compañía.`\n",
    "\n",
    "Las columnas `BA2` y `QF2` son redundantes. `BA2` contiene la respuesta de una pregunta de tipo SI/no y `QF2` tiene 1 o 0 dependendiendo del valor de la columna anterior.\n",
    "\n",
    "También voy a renombrar un par de columnas, ya que tienen un nombre muy largo (la pregunta entera que se hizo en la encuesta). Esto no va a influir en el algoritmo, pero me es más cómodo trabajar con columnas con nombres pequeños.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=mp.columns_to_delete, inplace=True)\n",
    "dataset.rename(mapper=mp.rename_dict, inplace=True)\n",
    "# There are values like spaces that we don't want, as they introduce some noise into the model\n",
    "dataset.replace(to_replace=' ', value=np.nan, inplace=True)\n"
   ]
  },
  {
   "source": [
    "Probando los valores únicos en las columnas, me di cuenta que la columna de género tiene géneros como `sí` y `no`. Estos valores no son válidos y antes de introducirlos así al algoritmo, vamos a considerar estos valores como valores perdidos, ya que no son validos. Lo hacemos justo antes de buscar los datos perdidos, si vemos que tras esta transformacion la columna contiene una gran cantidad de valores perdidos, se eliminará."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hombre' 'Mujer' nan 'No' 'Sí']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Género'].unique())\n",
    "dataset['Género'].replace(to_replace='Sí', value=np.nan, inplace=True)\n",
    "dataset['Género'].replace(to_replace='No', value=np.nan, inplace=True)"
   ]
  },
  {
   "source": [
    "### Eliminación de columnas con gran cantidad de valores perdidos.\n",
    "\n",
    "Revisando las columnas, he visto que hay varias columnas que solo contienen datos de un solo año. Esto es un problema, ya que dichas estas columnas van a tener una gran cantidad de valores perdidos. Imputar valores en dichas columnas no es una opción, ya que podemos introducir una gran cantidad de ruido en el dataset. Lo mejor es eliminarlas. \n",
    "A continuación se muestra cuales son dichas columnas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Columnas con más del 50% de valores perdidos:\n'Index(['Si el efectivo al final de un determinado periodo (día, mes, año,...) es mayor que al comienzo del periodo, significa que la empresa ha generado un beneficio positivo.',\n       'Una empresa acaba de adquirir un bien de equipo por el que ha pagado 200 euros. El bien será utilizado durante 5 años. El beneficio del ejercicio actual se verá reducido en:',\n       'El balance de situación es:',\n       '¿Cuál de las siguientes opciones describe mejor el ratio de rentabilidad sobre los activos (ROA)? ',\n       'No tener deuda es siempre una situación deseable para una empresa.',\n       'Cuando las ventas aumentan, significa que la empresa goza de buena salud.',\n       'La rentabilidad sobre activos se conoce como ROA, y la rentabilidad sobre los fondos propios invertidos por los accionistas en la empresa se conoce como ROE. Por regla general, el nivel de deuda es más sostenible si:',\n       'TotalEF (1-8)', 'EFB (1-3)', 'SumaEFA1_4', 'SumaEFA (1-5)', 'EFA5',\n       'EFA4', 'TotalEF1_4 (1-7)', 'EFA3', 'EFA2', 'EFA1', 'TotalFK (1-8)',\n       'GFK (1-4)', 'SumaBF (1-4)', 'IF1.6dTienes'],\n      dtype='object')'\n"
     ]
    }
   ],
   "source": [
    "lost_values = mp.get_missing_values(dataset, 0.5)\n",
    "print(f\"Columnas con más del 50% de valores perdidos:\\n'{lost_values}'\")\n",
    "\n",
    "dataset.drop(columns=lost_values, inplace=True)"
   ]
  },
  {
   "source": [
    "### Correlacion de columnas\n",
    "Vamos a calcular la correlacion que hay entre las columnas del dataset. Esto nos permitirá eliminar aquellas columnas que tengan una correlación alta.\n",
    "A continuación, se muestran las 20 columnas con una correlación más alta.\n",
    "\n",
    "Antes de seguir, vamos a separar las columnas que se van a usar como predictoras. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FI_Insur                 IF1.6jTiene              1.000000\nFinLit normaliz          FinLit total (1-19)      1.000000\nConFin (1_8)             ConFin (1_7)             0.987110\nFinBeh con borrow (1-7)  FinBehSinBorrow (1-6)    0.948779\nNSMedia                  NS2                      0.918361\nFI_Aware                 SumaConoces              0.892417\nNSMedia                  NS3                      0.891036\nSumaConoces              IF1.6iConoce             0.886519\nFI_Aware                 IF1.6cConoces            0.886250\nSumaConoces              IF1.6lConoce             0.878140\n                         IF1.6kConoce             0.877966\nAcMedia                  AC2                      0.877745\n                         AE5                      0.874652\nIF1.6lConoce             IF1.6kConoce             0.873608\nSEMedia                  SE3                      0.873497\nNSMedia                  NS1                      0.863767\nAcMedia                  AC3                      0.863616\nSumaConoces              IF1.6bConoces            0.862541\n                         IF1.6cConoces            0.860322\nTotalFKAdapt (1-8)       SumaBFAdapt (1-4)        0.854821\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the predictors data\n",
    "predictor_data = dataset[mp.predictors_name]\n",
    "dataset.drop(columns=mp.predictors_name, inplace=True)\n",
    "\n",
    "correlation_matrix = dataset.corr().abs()\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)).unstack().sort_values(kind=\"quicksort\", ascending=False)\n",
    "print(upper[:20])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Podemos ver que hay dos pares de columnas con una correlacion máxima: \n",
    "- `F1_Insur` y `IF1.6jTiene`: La columna `IF1.6jTiene` contiene informacion sobre si tienen un contrato de seguro y la columna `F1_Insur` va a ser 1 cuando tenga un seguro contratado. Asi que `F1_Insur` va a ser borrada.\n",
    "- `FinLit normaliz` y `FinLit total`: Respecto a estas dos, `FinLit normaliz` contiene la columna `FinLit` normalizada. Se va a borrar `FinLit normaliz`\n",
    "- `ConFin (1_8)` y `ConFin (1_7)` son columnas que contienen la suma de otras columnas, asi que ambas podrían ser eliminadas.\n",
    "También vamos a borrar unas columnas que contienen la suma y la media de ciertas columnas, ya que no proporcionan ninguna información.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3 features are highly correlated. They will be removed: ['ConFin (1_8)', 'FinLit normaliz', 'FI_Insur']\n"
     ]
    }
   ],
   "source": [
    "corr_cols = mp.get_highly_correlated_columns(dataset, 0.95)\n",
    "dataset.drop(columns=corr_cols, inplace=True)\n"
   ]
  },
  {
   "source": [
    "### Comprobar balance de clases\n",
    "Vamos a comprobar el balance de clases en las columnas que se van a usar como predictores. Necesitamos saber si estamos ante un problema de clasificación desbalanceado o no.\n",
    "Esta comprobación solo la vamos a hacer en las columnas que se van a usar para clasificación, ya que no tiene sentido ver la distribucion de clases para la variable que se usara para regresión."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64419d4198f94f09b8c0f83c38d8a012"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "fig = mp.print_distribution_class(predictor_data[mp.classification_predictor])\n"
   ]
  },
  {
   "source": [
    "En la gráfica de arriba, podemos ver que si que tenemos un desbalance de clases respecto a los valores `1.0`, `2.0`, `3.0`  en todas las variables predictoras. \n",
    "Este problema lo podemos afrontar realizando un `subsampling` en aquellas variables dominantes.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}